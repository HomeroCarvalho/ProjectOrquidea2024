\doxysection{F\+:/\+BACUKPS/\+Projeto\+Orquidea2024\+\_\+2/\+Project\+Orquidea2024/\+Project\+Orquidea2024/componentes\+De\+Interpretadores\+ECompiladores/\+PROGRAMACAO FUNCIONAL/\+Tokenizer.cs File Reference}
\hypertarget{_tokenizer_8cs}{}\label{_tokenizer_8cs}\index{F:/BACUKPS/ProjetoOrquidea2024\_2/ProjectOrquidea2024/ProjectOrquidea2024/componentesDeInterpretadoresECompiladores/PROGRAMACAO FUNCIONAL/Tokenizer.cs@{F:/BACUKPS/ProjetoOrquidea2024\_2/ProjectOrquidea2024/ProjectOrquidea2024/componentesDeInterpretadoresECompiladores/PROGRAMACAO FUNCIONAL/Tokenizer.cs}}
\doxysubsubsection*{Classes}
\begin{DoxyCompactItemize}
\item 
class \mbox{\hyperlink{classparser_1_1_tokenizer}{parser.\+Tokenizer}}
\begin{DoxyCompactList}\small\item\em o tokenizeer faz a retirada de tokens dentro de um texto, tendo como baliza os termos-\/chave da linguagem ao qual os tokens pertence. \end{DoxyCompactList}\item 
class \mbox{\hyperlink{classparser_1_1_tokenizer_1_1_testes}{parser.\+Tokenizer.\+Testes}}
\item 
class {\bfseries parser.\+Tokenizer.\+Token\+Com\+Posicao}
\item 
class {\bfseries parser.\+Tokenizer.\+Comparer\+Tokens\+Posicao}
\item 
class {\bfseries parser.\+Tokenizer.\+Comparer\+Texts}
\end{DoxyCompactItemize}
\doxysubsubsection*{Namespaces}
\begin{DoxyCompactItemize}
\item 
namespace \mbox{\hyperlink{namespaceparser}{parser}}
\end{DoxyCompactItemize}
